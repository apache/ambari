<?xml version="1.0"?>
<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<upgrade-config-changes xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="upgrade-config.xsd">
  <services>
    <service name="KAFKA">
      <component name="KAFKA_BROKER">
        <changes>
          <!-- BigInsights used to have security.inter.broker.protocol=SASL_PLAINTEXT but the preferred value in HDP 2.6
          is PLAINTEXTSASL and set also set listeners to use the same value, only when the cluster is kerberized. -->
          <definition xsi:type="configure" id="hdp_2_6_fix_kafka_protocol">
            <type>kafka-broker</type>
            <set key="security.inter.broker.protocol" value="PLAINTEXTSASL"/>
            <replace key="listeners" find="SASL_PLAINTEXT" replace-with="PLAINTEXTSASL"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="HDFS">
      <component name="NAMENODE">
        <changes>
          <definition xsi:type="configure" id="biginsights_4_2_namenode_update_hadoop_env" summary="Update Hadoop env">
            <type>hadoop-env</type>
            <replace key="content" find="export JAVA_LIBRARY_PATH=${JAVA_LIBRARY_PATH}:/usr/iop/current/hadoop-client/lib/native/Linux-amd64-64" replace-with="export JAVA_LIBRARY_PATH=${JAVA_LIBRARY_PATH}:{{hadoop_lib_home}}/native/Linux-{{architecture}}-64" />
            <replace key="content" find="export HADOOP_CLASSPATH=${HADOOP_CLASSPATH}${JAVA_JDBC_LIBS}:${MAPREDUCE_LIBS}" replace-with="export HADOOP_CLASSPATH=${HADOOP_CLASSPATH}${JAVA_JDBC_LIBS}:${MAPREDUCE_LIBS}&#10;if [ -d &quot;/usr/lib/hadoop-lzo&quot; ]; then&#10;  export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:/usr/lib/hadoop-lzo/lib/*&#10;  export JAVA_LIBRARY_PATH=${JAVA_LIBRARY_PATH}:/usr/lib/hadoop-lzo/lib/native&#10;fi"/>
            <insert key="content" value="{% if hadoop_custom_extensions_enabled %} export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:{{stack_root}}/current/ext/hadoop/* {% endif %}" insert-type="append" newline-after="true" newline-before="true"/>
          </definition>
          <definition xsi:type="configure" id="biginsights_4_2_namenode_adjustments">
            <type>hdfs-site</type>
            <transfer operation="delete" delete-key="dfs.namenode.rpc-address" if-type="hdfs-site" if-key="dfs.nameservices" if-key-state="present"/>
            <transfer operation="delete" delete-key="dfs.namenode.http-address" if-type="hdfs-site" if-key="dfs.nameservices" if-key-state="present"/>
            <transfer operation="delete" delete-key="dfs.namenode.https-address" if-type="hdfs-site" if-key="dfs.nameservices" if-key-state="present"/>
            <transfer operation="delete" delete-key="dfs.namenode.rpc-address" if-type="core-site" if-key="fs.defaultFS" if-key-state="present"/> <!-- Make sure to use the existing fs.defaultFS for the non-HA case -->
          </definition>
          <definition xsi:type="configure" id="hadoop_env_zkfc_security_opts" summary="Adding HDFS ZKFC Security ACLs">
            <type>hadoop-env</type>
            <insert key="content" value="{% if hadoop_zkfc_opts is defined %} export HADOOP_ZKFC_OPTS=&quot;{{hadoop_zkfc_opts}} $HADOOP_ZKFC_OPTS&quot; {% endif %}" insert-type="append" newline-before="true" newline-after="true" />
          </definition>
          <definition xsi:type="configure" id="biginsights_4_2_core_site_custom_extensions">
            <type>core-site</type>
            <set key="hadoop.custom-extensions.root" value="/hdp/ext/{{major_stack_version}}/hadoop" if-type="core-site" if-key="hadoop.custom-extensions.root" if-key-state="absent"/>
          </definition>

          <definition xsi:type="configure" id="hdp_2_6_0_0_remove_ranger_hdfs_audit_db">
            <type>ranger-hdfs-audit</type>
            <transfer operation="delete" delete-key="xasecure.audit.destination.db" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.url" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.user" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.password" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.driver" />
            <transfer operation="delete" delete-key="xasecure.audit.credential.provider.file" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.batch.filespool.dir" />
          </definition>
        </changes>
      </component>
    </service>
    
    <service name="YARN">
      <component name="RESOURCEMANAGER">
        <changes>
          <definition xsi:type="configure" id="biginsights_4_2_yarn_config_update" summary="Update Yarn configurations">
            <type>yarn-site</type>
            <!-- adjust the spark shuffle values for spark1 and spark2 -->
            <set key="yarn.nodemanager.aux-services" value="mapreduce_shuffle,spark_shuffle,spark2_shuffle"/>
            <set key="yarn.nodemanager.aux-services.spark_shuffle.class" value="org.apache.spark.network.yarn.YarnShuffleService"/>
            <set key="yarn.nodemanager.aux-services.spark_shuffle.classpath" value="{{stack_root}}/${hdp.version}/spark/aux/*"/>
            <set key="yarn.nodemanager.aux-services.spark2_shuffle.class" value="org.apache.spark.network.yarn.YarnShuffleService"/>
            <set key="yarn.nodemanager.aux-services.spark2_shuffle.classpath" value="{{stack_root}}/${hdp.version}/spark2/aux/*"/>
          </definition>
          <definition xsi:type="configure" id="yarn_env_security_opts" summary="Adding YARN Security ACLs">
            <type>yarn-env</type>
            <insert key="content" value="{% if rm_security_opts is defined %} YARN_OPTS=&quot;{{rm_security_opts}} $YARN_OPTS&quot; {% endif %}" insert-type="append" newline-before="true" newline-after="true" />
          </definition>

          <definition xsi:type="configure" id="hdp_2_6_0_0_remove_ranger_yarn_audit_db">
            <type>ranger-yarn-audit</type>
            <transfer operation="delete" delete-key="xasecure.audit.destination.db" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.url" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.user" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.password" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.driver" />
            <transfer operation="delete" delete-key="xasecure.audit.credential.provider.file" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.batch.filespool.dir" />
          </definition>
        </changes>
      </component>
    </service>

    <service name="MAPREDUCE2">
      <component name="HISTORYSERVER">
        <changes>
          <definition xsi:type="configure" id="biginsights_4_2_mapreduce_application_framework_patch" summary="Update MapReduce2 configurations">
            <type>mapred-site</type>
            <set key="mapreduce.application.framework.path" value="/hdp/apps/${hdp.version}/mapreduce/mapreduce.tar.gz#mr-framework"/>
            <set key="yarn.app.mapreduce.am.env" value="LD_LIBRARY_PATH=/usr/hdp/${hdp.version}/hadoop/lib/native:/usr/hdp/${hdp.version}/hadoop/lib/native/Linux-{{architecture}}-64"/>
          </definition>
        </changes>
      </component>
    </service>
    
    <service name="PIG">
      <component name="PIG">
        <changes>
          <definition xsi:type="configure" id="biginsights_4_2_pig_exectype_change" summary="Update Pig configurations">
            <type>pig-properties</type>
            <replace key="content" find="exectype=tez" replace-with="exectype=mapreduce"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="HBASE">
      <component name="HBASE_MASTER">
        <changes>
          <definition xsi:type="configure" id="biginsights_4_2_hbase_env_config" summary="Update HBase configurations">
            <type>hbase-env</type>
            <set key="backup_wal_dir" value="true"/>
          </definition>
          <definition xsi:type="configure" id="biginsights_4_2_hbase_site_custom_extensions" summary="Enable custom extension">
            <type>hbase-site</type>
            <set key="hbase.custom-extensions.root" value="/hdp/ext/{{major_stack_version}}/hbase" if-type="hbase-site" if-key-state="absent" if-key="hbase.custom-extensions.root"/>
          </definition>
          <definition xsi:type="configure" id="biginsights_4_2_hbase_env_custom_extensions" summary="Enable custom extensions">
            <type>hbase-env</type>
            <insert key="content" insert-type="append" value="# Extra Java CLASSPATH elements. Optional.&#10;export HBASE_CLASSPATH=${HBASE_CLASSPATH}:{{stack_root}}/current/ext/hbase/*" newline-after="true" newline-before="true"/>
          </definition>

          <definition xsi:type="configure" id="hdp_2_6_0_0_remove_ranger_hbase_audit_db">
            <type>ranger-hbase-audit</type>
            <transfer operation="delete" delete-key="xasecure.audit.destination.db" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.url" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.user" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.password" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.driver" />
            <transfer operation="delete" delete-key="xasecure.audit.credential.provider.file" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.batch.filespool.dir" />
          </definition>
        </changes>
      </component>
    </service>

    <service name="RANGER">
      <component name="RANGER_ADMIN">
        <changes>
          <definition xsi:type="configure" id="hdp_2_6_0_0_remove_bind_anonymous">
            <type>ranger-env</type>
            <transfer operation="delete" delete-key="bind_anonymous" />
          </definition>
          <definition xsi:type="configure" id="hdp_2_6_0_0_remove_ranger_solr_plugin_enabled_property">
            <type>ranger-env</type>
            <transfer operation="delete" delete-key="ranger-solr-plugin-enabled" if-type="ranger-env" if-key="ranger-solr-plugin-enabled" if-key-state="present" />
          </definition>
          <definition xsi:type="configure" id="admin_log4j_parameterize" summary="Parameterizing Ranger Log4J Properties">
            <type>admin-log4j</type>
            <set key="ranger_xa_log_maxfilesize" value="256"/>
            <set key="ranger_xa_log_maxbackupindex" value="20"/>
            <replace key="content" find="log4j.appender.xa_log_appender=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.xa_log_appender=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.xa_log_appender.MaxFileSize={{ranger_xa_log_maxfilesize}}MB"/>
            <replace key="content" find="log4j.appender.xa_log_appender=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.xa_log_appender=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.xa_log_appender.MaxBackupIndex={{ranger_xa_log_maxbackupindex}}"/>
          </definition>
        </changes>
      </component>
      <component name="RANGER_USERSYNC">
        <changes>
          <definition xsi:type="configure" id="usersync_log4j_parameterize" summary="Parameterizing Ranger Usersync Log4J Properties">
            <type>usersync-log4j</type>
            <set key="ranger_usersync_log_maxfilesize" value="256"/>
            <set key="ranger_usersync_log_maxbackupindex" value="20"/>
            <replace key="content" find="log4j.appender.logFile=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.logFile=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.logFile.MaxFileSize = {{ranger_usersync_log_maxfilesize}}MB"/>
            <replace key="content" find="log4j.appender.logFile=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.logFile=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.logFile.MaxBackupIndex = {{ranger_usersync_log_maxbackupindex}}"/>
          </definition>

          <definition xsi:type="configure" id="hdp_2_6_0_0_disable_delta_sync_during_upgrade">
            <type>ranger-ugsync-site</type>
            <set key="ranger.usersync.ldap.deltasync" value="false"
              if-type="ranger-ugsync-site" if-key="ranger.usersync.source.impl.class" if-value="org.apache.ranger.ldapusersync.process.LdapUserGroupBuilder"/>
          </definition>
        </changes>
      </component>
      <component name="RANGER_TAGSYNC">
        <changes>
          <definition xsi:type="configure" id="tagsync_log4j_parameterize" summary="Parameterizing Ranger Tagsync Log4J Properties">
            <type>tagsync-log4j</type>
            <set key="ranger_tagsync_log_maxfilesize" value="256"/>
            <set key="ranger_tagsync_log_number_of_backup_files" value="20"/>
            <replace key="content" find="log4j.appender.logFile=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.logFile=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.logFile.MaxFileSize = {{ranger_tagsync_log_maxfilesize}}MB"/>
            <replace key="content" find="log4j.appender.logFile=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.logFile=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.logFile.MaxBackupIndex = {{ranger_tagsync_log_number_of_backup_files}}"/>
          </definition>
        </changes>
      </component>
    </service>
    <service name="RANGER_KMS">
    <component name="RANGER_KMS_SERVER">
      <changes>
        <definition xsi:type="configure" id="kms_log4j_parameterize" summary="Parameterizing Ranger KMS Log4J Properties">
          <type>kms-log4j</type>
          <set key="ranger_kms_log_maxfilesize" value="256"/>
          <set key="ranger_kms_log_maxbackupindex" value="20"/>
          <set key="ranger_kms_audit_log_maxfilesize" value="256"/>
          <set key="ranger_kms_audit_log_maxbackupindex" value="20"/>
          <replace key="content" find="log4j.appender.kms=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.kms=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.kms.MaxFileSize = {{ranger_kms_log_maxfilesize}}MB"/>
          <replace key="content" find="log4j.appender.kms=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.kms=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.kms.MaxBackupIndex = {{ranger_kms_log_maxbackupindex}}"/>
          <replace key="content" find="log4j.appender.kms-audit=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.kms-audit=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.kms-audit.MaxFileSize = {{ranger_kms_audit_log_maxfilesize}}MB"/>
          <replace key="content" find="log4j.appender.kms-audit=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.kms-audit=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.kms-audit.MaxBackupIndex = {{ranger_kms_audit_log_maxbackupindex}}"/>
        </definition>
        <definition xsi:type="configure" id="hdp_2_6_0_0_remove_ranger_kms_duplicate_ssl">
          <type>ranger-kms-site</type>
          <transfer operation="delete" delete-key="ranger.https.attrib.keystore.file" if-type="ranger-kms-site" if-key="ranger.service.https.attrib.keystore.file" if-key-state="present"/>
          <transfer operation="delete" delete-key="ranger.service.https.attrib.clientAuth" if-type="ranger-kms-site" if-key="ranger.service.https.attrib.client.auth" if-key-state="present"/>
        </definition>
      </changes>
    </component>
    </service>

    <service name="HIVE">
      <component name="HIVE_CLIENT">
        <changes>
          <definition xsi:type="configure" id="biginsights_4_2_hive_exectype_change" summary="Update Hive Execution Engine">
            <type>hive-site</type>
            <set key="hive.execution.engine" value="mr" if-type="hive-site" if-key="hive.execution.engine" if-value="tez"/>
          </definition>
        </changes>
      </component>

      <component name="HIVE_SERVER">
        <changes>
          <definition xsi:type="configure" id="biginsights_4_2_hive_server_configure_authentication" summary="Configuring hive authentication">
            <type>hive-site</type>
            <transfer operation="delete" delete-key="hive.metastore.event.listeners" if-key="hive.metastore.event.listeners" if-type="hive-site" if-value="com.ibm.biginsights.bigsql.sync.BIEventListener"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.ldap.url" if-key="hive.server2.authentication" if-type="hive-site" if-value="NONE"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.ldap.baseDN" if-key="hive.server2.authentication" if-type="hive-site" if-value="NONE"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.pam.services" if-key="hive.server2.authentication" if-type="hive-site" if-value="NONE"/>
            <transfer operation="delete" delete-key="hive.server2.custom.authentication.class" if-key="hive.server2.authentication" if-type="hive-site" if-value="NONE"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.kerberos.keytab" if-key="hive.server2.authentication" if-type="hive-site" if-value="NONE"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.kerberos.principal" if-key="hive.server2.authentication" if-type="hive-site" if-value="NONE"/>

            <transfer operation="delete" delete-key="hive.server2.authentication.kerberos.keytab" if-key="hive.server2.authentication" if-type="hive-site" if-value="ldap"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.kerberos.principal" if-key="hive.server2.authentication" if-type="hive-site" if-value="ldap"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.pam.services" if-key="hive.server2.authentication" if-type="hive-site" if-value="ldap"/>
            <transfer operation="delete" delete-key="hive.server2.custom.authentication.class" if-key="hive.server2.authentication" if-type="hive-site" if-value="ldap"/>

            <transfer operation="delete" delete-key="hive.server2.authentication.ldap.url" if-key="hive.server2.authentication" if-type="hive-site" if-value="kerberos"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.ldap.baseDN" if-key="hive.server2.authentication" if-type="hive-site" if-value="kerberos"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.pam.services" if-key="hive.server2.authentication" if-type="hive-site" if-value="kerberos"/>
            <transfer operation="delete" delete-key="hive.server2.custom.authentication.class" if-key="hive.server2.authentication" if-type="hive-site" if-value="kerberos"/>

            <transfer operation="delete" delete-key="hive.server2.authentication.ldap.url" if-key="hive.server2.authentication" if-type="hive-site" if-value="pam"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.ldap.baseDN" if-key="hive.server2.authentication" if-type="hive-site" if-value="pam"/>
            <transfer operation="delete" delete-key="hive.server2.custom.authentication.class" if-key="hive.server2.authentication" if-type="hive-site" if-value="pam"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.kerberos.keytab" if-key="hive.server2.authentication" if-type="hive-site" if-value="pam"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.kerberos.principal" if-key="hive.server2.authentication" if-type="hive-site" if-value="pam"/>

            <transfer operation="delete" delete-key="hive.server2.authentication.ldap.url" if-key="hive.server2.authentication" if-type="hive-site" if-value="custom"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.ldap.baseDN" if-key="hive.server2.authentication" if-type="hive-site" if-value="custom"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.pam.services" if-key="hive.server2.authentication" if-type="hive-site" if-value="custom"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.kerberos.keytab" if-key="hive.server2.authentication" if-type="hive-site" if-value="custom"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.kerberos.principal" if-key="hive.server2.authentication" if-type="hive-site" if-value="custom"/>
          </definition>
          
          <definition xsi:type="configure" id="biginsights_4_2_hive_env_configure" summary="Configuring hive-env for MariaDB/RedHat7 support">
            <type>hive-env</type>
            <set key="mariadb_redhat_support" value="true"/>
          </definition>

          <definition xsi:type="configure" id="biginsights_4_2_hive_permissions" summary="Configuring hive-site permissions">
            <type>hive-site</type>
            <set key="custom.hive.warehouse.mode" value="0770" if-type="hive-site" if-key="custom.hive.warehouse.mode" if-key-state="absent"/>
          </definition>

          <definition xsi:type="configure" id="biginsights_4_2_hive_env_custom_extensions" summary="Enable custom extensions in hive-env">
            <type>hive-env</type>
            <replace key="content" find="if [ &quot;${HIVE_AUX_JARS_PATH}&quot; != &quot;&quot; ]; then" replace-with="export HIVE_AUX_JARS_PATH={{stack_root}}/current/ext/hive&#10;if [ &quot;${HIVE_AUX_JARS_PATH}&quot; != &quot;&quot; ]; then"/>
            <replace key="content" find="if [ -f &quot;${HIVE_AUX_JARS_PATH}&quot; ]; then" replace-with="if [ -f &quot;${HIVE_AUX_JARS_PATH}&quot; ] || [ -d &quot;${HIVE_AUX_JARS_PATH}&quot; ] ; then"/>
          </definition>

          <definition xsi:type="configure" id="hdp_2_6_0_0_remove_ranger_hive_audit_db">
            <type>ranger-hive-audit</type>
            <transfer operation="delete" delete-key="xasecure.audit.destination.db" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.url" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.user" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.password" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.driver" />
            <transfer operation="delete" delete-key="xasecure.audit.credential.provider.file" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.batch.filespool.dir" />
          </definition>
        </changes>
      </component>
      
      <component name="WEBHCAT_SERVER">
        <changes>
          <definition xsi:type="configure" id="biginsights_4_2_webhcat_server_update_environment_configurations" summary="Update Hadoop home">
            <type>webhcat-env</type>
            <replace key="content" find="export HADOOP_HOME={{hadoop_home}}" replace-with="export HADOOP_HOME=${HADOOP_HOME:-{{hadoop_home}}}" />
          </definition>
          
          <definition xsi:type="configure" id="biginsights_4_2_webhcat_server_update_configurations" summary="Updating Configuration Paths">
            <type>webhcat-site</type>
            <replace key="templeton.jar" find="/usr/iop/current/hive-webhcat" replace-with="/usr/hdp/${hdp.version}/hive"/>
            <replace key="templeton.libjars" find="/usr/iop/current/zookeeper-client" replace-with="/usr/hdp/${hdp.version}/zookeeper"/>
            <replace key="templeton.hadoop" find="/usr/iop/current/hadoop-client" replace-with="/usr/hdp/${hdp.version}/hadoop"/>
            <replace key="templeton.hcat" find="/usr/iop/current/hive-client" replace-with="/usr/hdp/${hdp.version}/hive"/>
          </definition>
        </changes>
      </component>
    </service>
    
    <service name="OOZIE">
      <component name="OOZIE_SERVER">
        <changes>
          <definition xsi:type="configure" id="biginsights_4_2_oozie_server_update_configurations" summary="Updating oozie-site configurations">
            <type>oozie-site</type>
            <replace key="oozie.services" find="org.apache.oozie.service.JvmPauseMonitorService" replace-with="org.apache.oozie.service.JvmPauseMonitorService,     org.apache.oozie.service.SparkConfigurationService"/>
          </definition>
          <definition xsi:type="configure" id="biginsights_4_2_oozie_server_update_environment_configurations" summary="Update oozie env">
            <type>oozie-env</type>
            <replace key="content" find="export CATALINA_BASE=${CATALINA_BASE:-{{oozie_server_dir}}}" replace-with="export CATALINA_BASE={{oozie_server_dir}}" />            
          </definition>
          <definition xsi:type="configure" id="biginsights_4_2_oozie_server_update_environment_tomcat" summary="Update oozie env">
            <type>oozie-env</type>
            <replace key="content" find="/usr/lib/bigtop-tomcat7-7.0.75" replace-with="/usr/lib/bigtop-tomcat" />
          </definition>
        </changes>
      </component>
    </service>
    
    <service name="SPARK2">
      <component name="SPARK2_CLIENT">
        <changes>
          <definition xsi:type="configure" id="hdp_2_6_0_0_spark2_defaults">
            <type>spark2-defaults</type>
            <set key="spark.yarn.queue" value="default" if-type="spark-defaults" if-key="spark.yarn.queue" if-key-state="absent"/>
            <transfer operation="delete" delete-key="spark.yarn.archive"/>
            <transfer operation="delete" delete-key="spark.thriftserver.ui.port"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="KNOX">
      <component name="KNOX_GATEWAY">
        <changes>
          <definition xsi:type="configure" id="hdp_2_6_0_0_remove_ranger_knox_audit_db">
            <type>ranger-knox-audit</type>
            <transfer operation="delete" delete-key="xasecure.audit.destination.db" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.url" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.user" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.password" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.driver" />
            <transfer operation="delete" delete-key="xasecure.audit.credential.provider.file" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.batch.filespool.dir" />
          </definition>
        </changes>
      </component>
    </service>
  </services>
</upgrade-config-changes>
