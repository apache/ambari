<?xml version="1.0"?>
<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<upgrade-config-changes xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="upgrade-config.xsd">
  <services>
    <service name="HBASE">
      <component name="HBASE_MASTER">
        <changes>
          <definition xsi:type="configure" id="hdp_2_3_4_0_hbase_remove_local_indexing">
            <type>hbase-site</type>
            <set key="phoenix.functions.allowUserDefinedFunctions" value="true"/>
            <transfer operation="delete" delete-key="hbase.master.loadbalancer.class"
                      if-key="hbase.master.loadbalancer.class"
                      if-type="hbase-site"
                      if-value="org.apache.phoenix.hbase.index.balancer.IndexLoadBalancer"/>
            <replace key="hbase.coprocessor.master.classes"
                     find="org.apache.phoenix.hbase.index.master.IndexMasterObserver"
                     replace-with=""/>
            <replace key="hbase.coprocessor.regionserver.classes"
                     find="org.apache.hadoop.hbase.regionserver.LocalIndexMerger"
                     replace-with=""/>

          </definition>
          <!-- These HBASE configs changed in HDP 2.3.4.0, so upgrades like HDP 2.2 to 2.4 still need them. -->
          <definition xsi:type="configure" id="hdp_2_4_0_0_hbase_remove_local_indexing">
            <type>hbase-site</type>
            <set key="phoenix.functions.allowUserDefinedFunctions" value="true"/>
            <transfer operation="delete" delete-key="hbase.master.loadbalancer.class"
                      if-key="hbase.master.loadbalancer.class"
                      if-type="hbase-site"
                      if-value="org.apache.phoenix.hbase.index.balancer.IndexLoadBalancer"/>
            <replace key="hbase.coprocessor.master.classes"
                     find="org.apache.phoenix.hbase.index.master.IndexMasterObserver"
                     replace-with="" />
            <replace key="hbase.coprocessor.regionserver.classes"
                     find="org.apache.hadoop.hbase.regionserver.LocalIndexMerger"
                     replace-with="" />

          </definition>

          <definition xsi:type="configure" id="hdp_2_5_0_0_remove_ranger_hbase_audit_db">
            <type>ranger-hbase-audit</type>
            <transfer operation="delete" delete-key="xasecure.audit.destination.db" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.url" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.user" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.password" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.driver" />
            <transfer operation="delete" delete-key="xasecure.audit.credential.provider.file" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.batch.filespool.dir" />
          </definition>

          <!-- HBase Rolling properties for log4j need to be parameterized. -->
          <definition xsi:type="configure" id="hbase_log4j_parameterize" summary="Parameterizing HBase Log4J Properties">
            <type>hbase-log4j</type>
            <set key="hbase_log_maxfilesize" value="256"/>
            <set key="hbase_log_maxbackupindex" value="20"/>
            <set key="hbase_security_log_maxfilesize" value="256"/>
            <set key="hbase_security_log_maxbackupindex" value="20"/>
            <regex-replace key="content" find="hbase.log.maxfilesize=([0-9]+)MB" replace-with="hbase.log.maxfilesize={{hbase_log_maxfilesize}}MB"/>
            <regex-replace key="content" find="hbase.log.maxbackupindex=([0-9]+)" replace-with="hbase.log.maxbackupindex={{hbase_log_maxbackupindex}}"/>
            <regex-replace key="content" find="hbase.security.log.maxfilesize=([0-9]+)MB" replace-with="hbase.security.log.maxfilesize={{hbase_security_log_maxfilesize}}MB"/>
            <regex-replace key="content" find="hbase.security.log.maxbackupindex=([0-9]+)" replace-with="hbase.security.log.maxbackupindex={{hbase_security_log_maxbackupindex}}"/>
          </definition>

        </changes>
      </component>
    </service>

    <service name="TEZ">
      <component name="TEZ_CLIENT">
        <changes>
          <definition xsi:type="configure" id="hdp_2_3_0_0_tez_client_adjust_tez_lib_uris_property">
            <type>tez-site</type>
            <set key="tez.lib.uris" value="/hdp/apps/${hdp.version}/tez/tez.tar.gz"/>
          </definition>
          <definition xsi:type="configure" id="hdp_2_4_0_0_tez_client_adjust_tez_lib_uris_property">
            <type>tez-site</type>
            <set key="tez.lib.uris" value="/hdp/apps/${hdp.version}/tez/tez.tar.gz"/>
          </definition>
          <definition xsi:type="configure" id="hdp_2_5_0_0_tez_client_adjust_tez_lib_uris_property">
            <type>tez-site</type>
            <set key="tez.lib.uris" value="/hdp/apps/${hdp.version}/tez/tez.tar.gz"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="SQOOP">
      <component name="SQOOP">
        <changes>
          <!-- All of these configs are present in Atlas' application.properties file instead and then copied to the hook's atlas-application.properties file. -->
          <definition xsi:type="configure" id="hdp_2_5_0_0_remove_sqoop_atlas_configs">
            <type>sqoop-site</type>
            <transfer operation="delete" delete-key="atlas.cluster.name" />
          </definition>

          <!-- Add these configs if the cluster is Kerberized.
          Will only be written to the local file system if Atlas is present. -->
          <definition xsi:type="configure" id="hdp_2_5_0_0_add_sqoop_atlas_security_configs">
            <type>sqoop-atlas-application.properties</type>
            <set key="atlas.jaas.KafkaClient.option.useTicketCache" value="true" 
              if-type="cluster-env" if-key="security_enabled" if-value="true"/>

            <set key="atlas.jaas.KafkaClient.option.renewTicket" value="true" 
              if-type="cluster-env" if-key="security_enabled" if-value="true"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="HIVE">
      <component name="HIVE_SERVER">
        <changes>
          <definition xsi:type="configure" id="hdp_2_4_0_0_hive_server_configure_authentication" summary="Removing unused properties for current hive authentication type">
            <type>hive-site</type>
            <transfer operation="delete" delete-key="hive.server2.authentication.ldap.url" if-key="hive.server2.authentication" if-type="hive-site" if-value="NONE"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.ldap.baseDN" if-key="hive.server2.authentication" if-type="hive-site" if-value="NONE"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.pam.services" if-key="hive.server2.authentication" if-type="hive-site" if-value="NONE"/>
            <transfer operation="delete" delete-key="hive.server2.custom.authentication.class" if-key="hive.server2.authentication" if-type="hive-site" if-value="NONE"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.kerberos.keytab" if-key="hive.server2.authentication" if-type="hive-site" if-value="NONE"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.kerberos.principal" if-key="hive.server2.authentication" if-type="hive-site" if-value="NONE"/>

            <transfer operation="delete" delete-key="hive.server2.authentication.kerberos.keytab" if-key="hive.server2.authentication" if-type="hive-site" if-value="ldap"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.kerberos.principal" if-key="hive.server2.authentication" if-type="hive-site" if-value="ldap"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.pam.services" if-key="hive.server2.authentication" if-type="hive-site" if-value="ldap"/>
            <transfer operation="delete" delete-key="hive.server2.custom.authentication.class" if-key="hive.server2.authentication" if-type="hive-site" if-value="ldap"/>

            <transfer operation="delete" delete-key="hive.server2.authentication.ldap.url" if-key="hive.server2.authentication" if-type="hive-site" if-value="kerberos"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.ldap.baseDN" if-key="hive.server2.authentication" if-type="hive-site" if-value="kerberos"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.pam.services" if-key="hive.server2.authentication" if-type="hive-site" if-value="kerberos"/>
            <transfer operation="delete" delete-key="hive.server2.custom.authentication.class" if-key="hive.server2.authentication" if-type="hive-site" if-value="kerberos"/>

            <transfer operation="delete" delete-key="hive.server2.authentication.ldap.url" if-key="hive.server2.authentication" if-type="hive-site" if-value="pam"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.ldap.baseDN" if-key="hive.server2.authentication" if-type="hive-site" if-value="pam"/>
            <transfer operation="delete" delete-key="hive.server2.custom.authentication.class" if-key="hive.server2.authentication" if-type="hive-site" if-value="pam"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.kerberos.keytab" if-key="hive.server2.authentication" if-type="hive-site" if-value="pam"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.kerberos.principal" if-key="hive.server2.authentication" if-type="hive-site" if-value="pam"/>

            <transfer operation="delete" delete-key="hive.server2.authentication.ldap.url" if-key="hive.server2.authentication" if-type="hive-site" if-value="custom"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.ldap.baseDN" if-key="hive.server2.authentication" if-type="hive-site" if-value="custom"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.pam.services" if-key="hive.server2.authentication" if-type="hive-site" if-value="custom"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.kerberos.keytab" if-key="hive.server2.authentication" if-type="hive-site" if-value="custom"/>
            <transfer operation="delete" delete-key="hive.server2.authentication.kerberos.principal" if-key="hive.server2.authentication" if-type="hive-site" if-value="custom"/>
          </definition>

          <definition xsi:type="configure" id="hdp_2_5_0_0_remove_ranger_hive_audit_db">
            <type>ranger-hive-audit</type>
            <transfer operation="delete" delete-key="xasecure.audit.destination.db" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.url" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.user" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.password" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.driver" />
            <transfer operation="delete" delete-key="xasecure.audit.credential.provider.file" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.batch.filespool.dir" />
          </definition>

          <!-- All of these configs are present in Atlas' application.properties file instead and then copied to the hook's atlas-application.properties file. -->
          <definition xsi:type="configure" id="hdp_2_5_0_0_remove_hive_atlas_configs">
            <type>hive-site</type>
            <transfer operation="delete" delete-key="atlas.rest.address" />
            <transfer operation="delete" delete-key="atlas.hook.hive.minThreads" />
            <transfer operation="delete" delete-key="atlas.hook.hive.maxThreads" />
          </definition>

        </changes>
      </component>
      <component name="WEBHCAT_SERVER">
        <changes>
          <definition xsi:type="configure" id="hdp_2_4_0_0_webhcat_server_update_configuration_paths" summary="Updating Configuration Paths">
            <type>webhcat-site</type>
            <replace key="templeton.jar" find="/usr/hdp/current/hive-webhcat" replace-with="/usr/hdp/${hdp.version}/hive"/>
            <replace key="templeton.libjars" find="/usr/hdp/current/zookeeper-client" replace-with="/usr/hdp/${hdp.version}/zookeeper,/usr/hdp/${hdp.version}/hive/lib/hive-common.jar"/>
            <replace key="templeton.hadoop" find="/usr/hdp/current/hadoop-client" replace-with="/usr/hdp/${hdp.version}/hadoop"/>
            <replace key="templeton.hcat" find="/usr/hdp/current/hive-client" replace-with="/usr/hdp/${hdp.version}/hive"/>
            <set key="templeton.hive.extra.files" value="/usr/hdp/${hdp.version}/tez/conf/tez-site.xml,/usr/hdp/${hdp.version}/tez,/usr/hdp/${hdp.version}/tez/lib"/>
          </definition>

          <definition xsi:type="configure" id="hdp_2_5_0_0_webhcat_server_update_configuration_paths" summary="Updating Configuration Paths">
            <type>webhcat-site</type>
            <replace key="templeton.jar" find="/usr/hdp/current/hive-webhcat" replace-with="/usr/hdp/${hdp.version}/hive"/>
            <replace key="templeton.libjars" find="/usr/hdp/current/zookeeper-client" replace-with="/usr/hdp/${hdp.version}/zookeeper,/usr/hdp/${hdp.version}/hive/lib/hive-common.jar"/>
            <replace key="templeton.hadoop" find="/usr/hdp/current/hadoop-client" replace-with="/usr/hdp/${hdp.version}/hadoop"/>
            <replace key="templeton.hcat" find="/usr/hdp/current/hive-client" replace-with="/usr/hdp/${hdp.version}/hive"/>
            <set key="templeton.hive.extra.files" value="/usr/hdp/${hdp.version}/tez/conf/tez-site.xml,/usr/hdp/${hdp.version}/tez,/usr/hdp/${hdp.version}/tez/lib"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="RANGER">
      <component name="RANGER_ADMIN">
        <changes>

          <definition xsi:type="configure" id="hdp_2_5_0_0_remove_audit_db_flag">
            <type>ranger-env</type>
            <transfer operation="delete" delete-key="xasecure.audit.destination.db"/>
          </definition>

          <definition xsi:type="configure" id="hdp_2_5_0_0_remove_audit_db_admin_properties">
            <type>admin-properties</type>
            <transfer operation="delete" delete-key="audit_db_name" />
            <transfer operation="delete" delete-key="audit_db_user" />
            <transfer operation="delete" delete-key="audit_db_password" />
          </definition>

          <definition xsi:type="configure" id="hdp_2_5_0_0_remove_audit_db_ranger_admin_site">
            <type>ranger-admin-site</type>
            <set key="ranger.audit.source.type" value="solr"/>
            <transfer operation="delete" delete-key="ranger.jpa.audit.jdbc.driver" />
            <transfer operation="delete" delete-key="ranger.jpa.audit.jdbc.url" />
            <transfer operation="delete" delete-key="ranger.jpa.audit.jdbc.user" />
            <transfer operation="delete" delete-key="ranger.jpa.audit.jdbc.password" />
            <transfer operation="delete" delete-key="ranger.jpa.audit.jdbc.credential.alias" />
            <transfer operation="delete" delete-key="ranger.jpa.audit.jdbc.dialect" />
          </definition>

          <definition xsi:type="configure" id="hdp_2_5_0_0_remove_sso_property">
            <type>ranger-admin-site</type>
            <transfer operation="delete" delete-key="ranger.sso.cookiename" />
            <transfer operation="delete" delete-key="ranger.sso.query.param.originalurl" />
          </definition>

          <definition xsi:type="configure" id="hdp_2_5_0_0_set_external_solrCloud_flag">
            <type>ranger-env</type>            
            <set key="is_external_solrCloud_enabled" value="true" 
              if-type="ranger-env" if-key="is_solrCloud_enabled" if-value="true"/>
          </definition>

          <definition xsi:type="configure" id="hdp_2_6_0_0_remove_bind_anonymous">
            <type>ranger-env</type>
            <transfer operation="delete" delete-key="bind_anonymous" />
          </definition>
          <definition xsi:type="configure" id="admin_log4j_parameterize" summary="Parameterizing Ranger Log4J Properties">
            <type>admin-log4j</type>
            <set key="ranger_xa_log_maxfilesize" value="256"/>
            <set key="ranger_xa_log_maxbackupindex" value="20"/>
            <replace key="content" find="log4j.appender.xa_log_appender=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.xa_log_appender=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.xa_log_appender.MaxFileSize={{ranger_xa_log_maxfilesize}}MB"/>
            <replace key="content" find="log4j.appender.xa_log_appender=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.xa_log_appender=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.xa_log_appender.MaxBackupIndex={{ranger_xa_log_maxbackupindex}}"/>
          </definition>

        </changes>
      </component>

      <component name="RANGER_USERSYNC">
        <changes>
          <definition xsi:type="configure" id="usersync_log4j_parameterize" summary="Parameterizing Ranger Usersync Log4J Properties">
            <type>usersync-log4j</type>
            <set key="ranger_usersync_log_maxfilesize" value="256"/>
            <set key="ranger_usersync_log_maxbackupindex" value="20"/>
            <replace key="content" find="log4j.appender.logFile=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.logFile=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.logFile.MaxFileSize = {{ranger_usersync_log_maxfilesize}}MB"/>
            <replace key="content" find="log4j.appender.logFile=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.logFile=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.logFile.MaxBackupIndex = {{ranger_usersync_log_maxbackupindex}}"/>
          </definition>
        </changes>
      </component>

      <component name="RANGER_TAGSYNC">
        <changes>
          <definition xsi:type="configure" id="tagsync_log4j_parameterize" summary="Parameterizing Ranger Tagsync Log4J Properties">
            <type>tagsync-log4j</type>
            <set key="ranger_tagsync_log_maxfilesize" value="256"/>
            <set key="ranger_tagsync_log_number_of_backup_files" value="20"/>
            <replace key="content" find="log4j.appender.logFile=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.logFile=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.logFile.MaxFileSize = {{ranger_tagsync_log_maxfilesize}}MB"/>
            <replace key="content" find="log4j.appender.logFile=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.logFile=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.logFile.MaxBackupIndex = {{ranger_tagsync_log_number_of_backup_files}}"/>
          </definition>
          </changes>
      </component>
    </service>

    <service name="RANGER_KMS">
      <component name="RANGER_KMS_SERVER">
        <changes>
          <definition xsi:type="configure" id="hdp_2_5_0_0_remove_ranger_kms_audit_db">
            <type>ranger-kms-audit</type>
            <transfer operation="delete" delete-key="xasecure.audit.destination.db" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.url" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.user" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.password" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.driver" />
            <transfer operation="delete" delete-key="xasecure.audit.credential.provider.file" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.batch.filespool.dir" />
          </definition>
          <definition xsi:type="configure" id="kms_log4j_parameterize" summary="Parameterizing Ranger KMS Log4J Properties">
            <type>kms-log4j</type>
            <set key="ranger_kms_log_maxfilesize" value="256"/>
            <set key="ranger_kms_log_maxbackupindex" value="20"/>
            <set key="ranger_kms_audit_log_maxfilesize" value="256"/>
            <set key="ranger_kms_audit_log_maxbackupindex" value="20"/>
            <replace key="content" find="log4j.appender.kms=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.kms=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.kms.MaxFileSize = {{ranger_kms_log_maxfilesize}}MB"/>
            <replace key="content" find="log4j.appender.kms=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.kms=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.kms.MaxBackupIndex = {{ranger_kms_log_maxbackupindex}}"/>
            <replace key="content" find="log4j.appender.kms-audit=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.kms-audit=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.kms-audit.MaxFileSize = {{ranger_kms_audit_log_maxfilesize}}MB"/>
            <replace key="content" find="log4j.appender.kms-audit=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.kms-audit=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.kms-audit.MaxBackupIndex = {{ranger_kms_audit_log_maxbackupindex}}"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="HDFS">
      <component name="NAMENODE">
        <changes>
          <definition xsi:type="configure" id="hdp_2_4_0_0_namenode_ha_adjustments">
            <type>hdfs-site</type>
            <transfer operation="delete" delete-key="dfs.namenode.rpc-address" if-type="hdfs-site" if-key="dfs.nameservices" if-key-state="present"/>
            <transfer operation="delete" delete-key="dfs.namenode.http-address" if-type="hdfs-site" if-key="dfs.nameservices" if-key-state="present"/>
            <transfer operation="delete" delete-key="dfs.namenode.https-address" if-type="hdfs-site" if-key="dfs.nameservices" if-key-state="present"/>
          </definition>

          <definition xsi:type="configure" id="hdp_2_5_0_0_remove_ranger_hdfs_audit_db">
            <type>ranger-hdfs-audit</type>
            <transfer operation="delete" delete-key="xasecure.audit.destination.db" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.url" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.user" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.password" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.driver" />
            <transfer operation="delete" delete-key="xasecure.audit.credential.provider.file" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.batch.filespool.dir" />
          </definition>

          <!-- HDFS Rolling properties for log4j need to be parameterized. -->
          <definition xsi:type="configure" id="hdfs_log4j_parameterize" summary="Parameterizing Hdfs Log4J Properties">
            <type>hdfs-log4j</type>
            <set key="hadoop_log_max_backup_size" value="256"/>
            <set key="hadoop_log_number_of_backup_files" value="10"/>
            <set key="hadoop_security_log_max_backup_size" value="256"/>
            <set key="hadoop_security_log_number_of_backup_files" value="20"/>
            <regex-replace  key="content" find="log4j.appender.RFA.MaxFileSize=([0-9]+)MB" replace-with="log4j.appender.RFA.MaxFileSize={{hadoop_log_max_backup_size}}MB"/>
            <regex-replace  key="content" find="log4j.appender.RFA.MaxBackupIndex=([0-9]+)" replace-with="log4j.appender.RFA.MaxBackupIndex={{hadoop_log_number_of_backup_files}}"/>
            <regex-replace  key="content" find="hadoop.security.log.maxfilesize=([0-9]+)MB" replace-with="hadoop.security.log.maxfilesize={{hadoop_security_log_max_backup_size}}MB"/>
            <regex-replace  key="content" find="hadoop.security.log.maxbackupindex=([0-9]+)" replace-with="hadoop.security.log.maxbackupindex={{hadoop_security_log_number_of_backup_files}}"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="SPARK">
      <component name="SPARK_JOBHISTORYSERVER">
        <changes>
          <definition xsi:type="configure" id="hdp_2_4_0_0_spark_jobhistoryserver">
            <type>spark-defaults</type>
            <transfer operation="delete" delete-key="spark.yarn.services" />
            <transfer operation="delete" delete-key="spark.driver.extraJavaOptions" />
            <transfer operation="delete" delete-key="spark.yarn.am.extraJavaOptions" />
            <set key="spark.history.provider" value="org.apache.spark.deploy.history.FsHistoryProvider"/>
          </definition>
          <definition xsi:type="configure" id="hdp_2_4_0_0_spark_java_opts">
            <type>spark-javaopts-properties</type>
            <transfer operation="delete" delete-key="content" />
          </definition>
        </changes>
      </component>
      <component name="SPARK_CLIENT">
        <changes>
          <definition xsi:type="configure" id="hdp_2_4_0_0_remove_spark_properties_extraJavaOptions">
            <type>spark-defaults</type>
            <transfer operation="delete" delete-key="spark.driver.extraJavaOptions" />
            <transfer operation="delete" delete-key="spark.yarn.am.extraJavaOptions" />
          </definition>
          <definition xsi:type="configure" id="hdp_2_4_0_0_spark_java_opts">
            <type>spark-javaopts-properties</type>
            <transfer operation="delete" delete-key="content" />
          </definition>
        </changes>
      </component>
      <component name="SPARK_THRIFTSERVER">
        <changes>
          <definition xsi:type="configure" id="hdp_2_4_0_0_spark_thriftserver">
            <type>spark-thrift-sparkconf</type>
            <transfer operation="delete" delete-key="spark.yarn.executor.memoryOverhead" />
            <transfer operation="delete" delete-key="spark.yarn.driver.memoryOverhead" />
            <transfer operation="delete" delete-key="spark.yarn.scheduler.heartbeat.interval-ms" />
            <transfer operation="delete" delete-key="spark.yarn.max.executor.failures" />
            <transfer operation="delete" delete-key="spark.yarn.containerLauncherMaxThreads" />
            <transfer operation="delete" delete-key="spark.yarn.submit.file.replication" />
            <transfer operation="delete" delete-key="spark.yarn.preserve.staging.files" />
            <transfer operation="delete" delete-key="spark.yarn.max.executor.failures" />
            <transfer operation="delete" delete-key="spark.driver.extraJavaOptions" />
            <transfer operation="delete" delete-key="spark.yarn.am.extraJavaOptions" />
          </definition>
          <definition xsi:type="configure" id="hdp_2_4_0_0_spark_java_opts">
            <type>spark-javaopts-properties</type>
            <transfer operation="delete" delete-key="content" />
          </definition>
        </changes>
      </component>
    </service>

    <service name="OOZIE">
      <component name="OOZIE_SERVER">
        <changes>
          <definition xsi:type="configure" id="hdp_2_4_0_0_oozie_remove_service_classes" summary="Updating Oozie Service classes">
            <type>oozie-site</type>
            <replace key="oozie.services" find="org.apache.oozie.service.CoordinatorStoreService," replace-with="" />
          </definition>
          <!-- Oozie Rolling properties for log4j need to be parameterized. -->
          <definition xsi:type="configure" id="oozie_log4j_parameterize" summary="Parameterizing Oozie Log4J Properties">
            <type>oozie-log4j</type>
            <set key="oozie_log_maxhistory" value="720"/>
            <regex-replace key="content" find="^log4j.appender.oozie.RollingPolicy.MaxHistory=([0-9]+)" replace-with="log4j.appender.oozie.RollingPolicy.MaxHistory={{oozie_log_maxhistory}}"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="KAFKA">
      <component name="KAFKA_BROKER">
        <changes>
          <definition xsi:type="configure" id="hdp_2_5_0_0_remove_ranger_kafka_audit_db">
            <type>ranger-kafka-audit</type>
            <transfer operation="delete" delete-key="xasecure.audit.destination.db" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.url" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.user" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.password" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.driver" />
            <transfer operation="delete" delete-key="xasecure.audit.credential.provider.file" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.batch.filespool.dir" />
          </definition>
          <definition xsi:type="configure" id="hdp_2_5_0_0_add_protocol_compatibility">
            <type>kafka-broker</type>
            <set key="inter.broker.protocol.version" value="0.9.0.0" />
            <set key="log.message.format.version" value="0.9.0.0" />
          </definition>
          <definition xsi:type="configure" id="kafka_log4j_parameterize" summary="Parameterizing Kafka Log4J Properties">
            <type>kafka-log4j</type>
            <set key="kafka_log_maxfilesize" value="256"/>
            <set key="kafka_log_maxbackupindex" value="20"/>
            <set key="controller_log_maxfilesize" value="256"/>
            <set key="controller_log_maxbackupindex" value="20"/>
            <replace key="content" find="log4j.appender.kafkaAppender=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.kafkaAppender=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.kafkaAppender.MaxFileSize = {{kafka_log_maxfilesize}}MB"/>
            <replace key="content" find="log4j.appender.kafkaAppender=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.kafkaAppender=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.kafkaAppender.MaxBackupIndex = {{kafka_log_maxbackupindex}}"/>
            <replace key="content" find="log4j.appender.controllerAppender=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.controllerAppender=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.controllerAppender.MaxFileSize = {{controller_log_maxfilesize}}MB"/>
            <replace key="content" find="log4j.appender.controllerAppender=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.controllerAppender=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.controllerAppender.MaxBackupIndex = {{controller_log_maxbackupindex}}"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="YARN">
      <component name="RESOURCEMANAGER">
        <changes>
          <definition xsi:type="configure" id="hdp_2_5_0_0_remove_ranger_yarn_audit_db">
            <type>ranger-yarn-audit</type>
            <transfer operation="delete" delete-key="xasecure.audit.destination.db" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.url" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.user" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.password" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.driver" />
            <transfer operation="delete" delete-key="xasecure.audit.credential.provider.file" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.batch.filespool.dir" />
          </definition>
          <!-- Yarn Rolling properties for log4j need to be parameterized. -->
          <definition xsi:type="configure" id="yarn_log4j_parameterize" summary="Parameterizing Yarn Log4J Properties">
            <type>yarn-log4j</type>
            <set key="yarn_rm_summary_log_max_backup_size" value="256"/>
            <set key="yarn_rm_summary_log_number_of_backup_files" value="20"/>
            <regex-replace key="content" find="^log4j.appender.RMSUMMARY.MaxFileSize=([0-9]+)MB" replace-with="log4j.appender.RMSUMMARY.MaxFileSize={{yarn_rm_summary_log_max_backup_size}}MB"/>
            <regex-replace key="content" find="^log4j.appender.RMSUMMARY.MaxBackupIndex=([0-9]+)" replace-with="log4j.appender.RMSUMMARY.MaxBackupIndex={{yarn_rm_summary_log_number_of_backup_files}}"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="STORM">
      <component name="NIMBUS">
        <changes>
          <definition xsi:type="configure" id="hdp_2_5_0_0_remove_ranger_storm_audit_db">
            <type>ranger-storm-audit</type>
            <transfer operation="delete" delete-key="xasecure.audit.destination.db" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.url" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.user" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.password" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.driver" />
            <transfer operation="delete" delete-key="xasecure.audit.credential.provider.file" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.batch.filespool.dir" />
          </definition>

          <definition xsi:type="configure" id="hdp_2_5_0_0_upgrade_storm_1.0">
            <type>storm-site</type>
            <replace key="_storm.thrift.nonsecure.transport" find="backtype.storm.security.auth.SimpleTransportPlugin"
                     replace-with="org.apache.storm.security.auth.SimpleTransportPlugin" />
            <replace key="_storm.thrift.secure.transport" find="backtype.storm.security.auth.KerberosSaslTransportPlugin"
                     replace-with="org.apache.storm.security.auth.KerberosSaslTransportPlugin" />
            <replace key="storm.messaging.transport" find="backtype.storm.messaging.netty.Context"
                     replace-with="org.apache.storm.messaging.netty.Context" />
            <replace key="nimbus.topology.validator" find="backtype.storm.nimbus.DefaultTopologyValidator"
                     replace-with="org.apache.storm.nimbus.DefaultTopologyValidator" />
            <replace key="topology.spout.wait.strategy" find="backtype.storm.spout.SleepSpoutWaitStrategy"
                     replace-with="org.apache.storm.spout.SleepSpoutWaitStrategy" />
            <replace key="topology.kryo.factory" find="backtype.storm.serialization.DefaultKryoFactory"
                     replace-with="org.apache.storm.serialization.DefaultKryoFactory" />
            <replace key="topology.tuple.serializer" find="backtype.storm.serialization.types.ListDelegateSerializer"
                     replace-with="org.apache.storm.serialization.types.ListDelegateSerializer" />
            <replace key="nimbus.authorizer" find="backtype.storm.security.auth.authorizer.SimpleACLAuthorizer"
                     replace-with="org.apache.storm.security.auth.authorizer.SimpleACLAuthorizer" />
            <replace key="drpc.authorizer" find="backtype.storm.security.auth.authorizer.DRPCSimpleACLAuthorizer"
                     replace-with="org.apache.storm.security.auth.authorizer.DRPCSimpleACLAuthorizer" />
            <replace key="ui.filter" find="backtype.storm.security.auth.KerberosPrincipalToLocal"
                     replace-with="org.apache.storm.security.auth.KerberosPrincipalToLocal" />
            <replace key="storm.principal.tolocal" find="backtype.storm.security.auth.KerberosPrincipalToLocal"
                     replace-with="org.apache.storm.security.auth.KerberosPrincipalToLocal" />
            <set key="client.jartransformer.class" value="org.apache.storm.hack.StormShadeTransformer" />
          </definition>

          <definition xsi:type="configure" id="hdp_2_5_0_0_add_storm_security_configs">
            <type>storm-site</type>
            <set key="nimbus.impersonation.authorizer" value="org.apache.storm.security.auth.authorizer.ImpersonationAuthorizer" if-type="cluster-env" if-key="security_enabled" if-value="true" />
            <set key="nimbus.impersonation.acl" value="{ {{storm_bare_jaas_principal}} : {hosts: ['*'], groups: ['*']}}" if-type="cluster-env" if-key="security_enabled" if-value="true" />
            <set key="nimbus.admins" value="['{{storm_bare_jaas_principal}}', '{{ambari_bare_jaas_principal}}']" if-type="cluster-env" if-key="security_enabled" if-value="true" />
          </definition>

          <definition xsi:type="configure" id="hdp_2_3_0_0_remove_empty_storm_topology_submission_notifier_plugin_class"
                      summary="Removing empty storm.topology.submission.notifier.plugin.class property">
            <type>storm-site</type>
            <transfer operation="delete" delete-key="storm.topology.submission.notifier.plugin.class" if-key="storm.topology.submission.notifier.plugin.class"
                      if-type="storm-site" if-value=" "/>
          </definition>

          <!-- All of these configs are present in Atlas' application.properties file instead and then copied to the hook's atlas-application.properties file. -->
          <definition xsi:type="configure" id="hdp_2_5_0_0_remove_storm_atlas_configs">
            <type>storm-site</type>
            <transfer operation="delete" delete-key="atlas.cluster.name" />
          </definition>
          <definition xsi:type="configure" id="increase_storm_zookeeper_timeouts"
                      summary="Increase storm.zookeeper.session.timeout and storm.zookeeper.connection.timeout property">
            <type>storm-site</type>
            <set key="storm.zookeeper.session.timeout"
                 value="30000"
                 if-key="storm.zookeeper.session.timeout"
                 if-type="storm-site"
                 if-value="20000" />
            <set key="storm.zookeeper.connection.timeout"
                 value="30000"
                 if-key="storm.zookeeper.connection.timeout"
                 if-type="storm-site"
                 if-value="15000" />
          </definition>
        </changes>
      </component>
    </service>

    <service name="KNOX">
      <component name="KNOX_GATEWAY">
        <changes>
          <definition xsi:type="configure" id="hdp_2_5_0_0_remove_ranger_knox_audit_db">
            <type>ranger-knox-audit</type>
            <transfer operation="delete" delete-key="xasecure.audit.destination.db" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.url" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.user" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.password" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.jdbc.driver" />
            <transfer operation="delete" delete-key="xasecure.audit.credential.provider.file" />
            <transfer operation="delete" delete-key="xasecure.audit.destination.db.batch.filespool.dir" />
          </definition>
          <definition xsi:type="configure" id="knox_gateway_log4j_parameterize" summary="Parameterizing Knox Gateway Log4J Properties">
            <type>gateway-log4j</type>
            <set key="knox_gateway_log_maxfilesize" value="256"/>
            <set key="knox_gateway_log_maxbackupindex" value="20"/>
            <replace key="content" find="log4j.appender.drfa=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.drfa=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.drfa.MaxFileSize = {{knox_gateway_log_maxfilesize}}MB"/>
            <replace key="content" find="log4j.appender.drfa=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.drfa=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.drfa.MaxBackupIndex = {{knox_gateway_log_maxbackupindex}}"/>
          </definition>
          <definition xsi:type="configure" id="knox_ldap_log4j_parameterize" summary="Parameterizing Knox Ldap Log4J Properties">
            <type>ldap-log4j</type>
            <set key="knox_ldap_log_maxfilesize" value="256"/>
            <set key="knox_ldap_log_maxbackupindex" value="20"/>
            <replace key="content" find="log4j.appender.drfa=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.drfa=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.drfa.MaxFileSize = {{knox_ldap_log_maxfilesize}}MB"/>
            <replace key="content" find="log4j.appender.drfa=org.apache.log4j.DailyRollingFileAppender" replace-with="log4j.appender.drfa=org.apache.log4j.DailyRollingFileAppender&#xA;log4j.appender.drfa.MaxBackupIndex = {{knox_ldap_log_maxbackupindex}}"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="FALCON">
      <component name="FALCON_SERVER">
        <changes>
          <definition xsi:type="configure" id="hdp_2_5_0_0_falcon_server_adjust_services_property">
            <type>falcon-startup.properties</type>
            <set key="*.application.services" value="org.apache.falcon.security.AuthenticationInitializationService, org.apache.falcon.workflow.WorkflowJobEndNotificationService, org.apache.falcon.service.ProcessSubscriberService, org.apache.falcon.extensions.ExtensionService, org.apache.falcon.service.LifecyclePolicyMap, org.apache.falcon.entity.store.ConfigurationStore, org.apache.falcon.rerun.service.RetryService, org.apache.falcon.rerun.service.LateRunService, org.apache.falcon.service.LogCleanupService, org.apache.falcon.metadata.MetadataMappingService{{atlas_application_class_addition}}"/>
          </definition>
          <definition xsi:type="configure" id="falcon_log4j_parameterize" summary="Parameterizing Falcon Log4J Properties">
            <type>falcon-log4j</type>
            <set key="falcon_log_maxfilesize" value="256"/>
            <set key="falcon_log_maxbackupindex" value="20"/>
            <set key="falcon_security_log_maxfilesize" value="256"/>
            <set key="falcon_security_log_maxbackupindex" value="20"/>
            <replace key="content" find="&lt;appender name=&quot;FILE&quot; class=&quot;org.apache.log4j.DailyRollingFileAppender&quot;&gt;" replace-with="&lt;appender name=&quot;FILE&quot; class=&quot;org.apache.log4j.DailyRollingFileAppender&quot;&gt;&#xA;&lt;param name=&quot;MaxFileSize&quot; value=&quot;{{falcon_log_maxfilesize}}MB&quot; /&gt;"/>
            <replace key="content" find="&lt;appender name=&quot;FILE&quot; class=&quot;org.apache.log4j.DailyRollingFileAppender&quot;&gt;" replace-with="&lt;appender name=&quot;FILE&quot; class=&quot;org.apache.log4j.DailyRollingFileAppender&quot;&gt;&#xA;&lt;param name=&quot;MaxBackupIndex&quot; value=&quot;{{falcon_log_maxbackupindex}}&quot; /&gt;"/>
            <replace key="content" find="&lt;appender name=&quot;SECURITY&quot; class=&quot;org.apache.log4j.DailyRollingFileAppender&quot;&gt;" replace-with="&lt;appender name=&quot;SECURITY&quot; class=&quot;org.apache.log4j.DailyRollingFileAppender&quot;&gt;&#xA;&lt;param name=&quot;MaxFileSize&quot; value=&quot;{{falcon_security_log_maxfilesize}}MB&quot;/&gt;"/>
            <replace key="content" find="&lt;appender name=&quot;SECURITY&quot; class=&quot;org.apache.log4j.DailyRollingFileAppender&quot;&gt;" replace-with="&lt;appender name=&quot;SECURITY&quot; class=&quot;org.apache.log4j.DailyRollingFileAppender&quot;&gt;&#xA;&lt;param name=&quot;MaxBackupIndex&quot; value=&quot;{{falcon_security_log_maxbackupindex}}&quot;/&gt;"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="ATLAS">
      <component name="ATLAS_SERVER">
        <changes>
          <definition xsi:type="configure" id="atlas_log4j_parameterize" summary="Parameterizing Atlas Log4J Properties">
            <type>atlas-log4j</type>
            <set key="atlas_log_max_backup_size" value="256"/>
            <set key="atlas_log_number_of_backup_files" value="20"/>
            <replace key="content" find="&lt;appender name=&quot;FILE&quot; class=&quot;org.apache.log4j.DailyRollingFileAppender&quot;&gt;" replace-with="&lt;appender name=&quot;FILE&quot; class=&quot;org.apache.log4j.DailyRollingFileAppender&quot;&gt;\n&lt;param name=&quot;MaxFileSize&quot; value=&quot;{{atlas_log_max_backup_size}}MB&quot; /&gt;"/>
            <replace key="content" find="&lt;appender name=&quot;FILE&quot; class=&quot;org.apache.log4j.DailyRollingFileAppender&quot;&gt;" replace-with="&lt;appender name=&quot;FILE&quot; class=&quot;org.apache.log4j.DailyRollingFileAppender&quot;&gt;\n&lt;param name=&quot;MaxFileSize&quot; value=&quot;{{atlas_log_number_of_backup_files}}&quot; /&gt;"/>
          </definition>
        </changes>
      </component>
    </service>

    <service name="ZOOKEEPER">
      <component name="ZOOKEEPER_SERVER">
        <changes>
          <!-- Zookeeper Rolling properties for log4j need to be parameterized. -->
          <definition xsi:type="configure" id="zookeeper_log4j_parameterize" summary="Parameterizing ZooKeeper Log4J Properties">
            <type>zookeeper-log4j</type>
            <set key="zookeeper_log_max_backup_size" value="10"/>
            <set key="zookeeper_log_number_of_backup_files" value="10"/>
            <regex-replace  key="content" find="^log4j.appender.ROLLINGFILE.MaxFileSize=([0-9]+)MB" replace-with="log4j.appender.ROLLINGFILE.MaxFileSize={{zookeeper_log_max_backup_size}}MB"/>
            <regex-replace key="content" find="^#log4j.appender.ROLLINGFILE.MaxBackupIndex=([0-9]+)" replace-with="#log4j.appender.ROLLINGFILE.MaxBackupIndex={{zookeeper_log_number_of_backup_files}}"/>
          </definition>
        </changes>
      </component>
    </service>

  </services>
</upgrade-config-changes>
