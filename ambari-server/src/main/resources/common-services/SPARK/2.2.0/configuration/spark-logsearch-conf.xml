<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
<configuration supports_final="false" supports_adding_forbidden="true">
  <property>
    <name>service_name</name>
    <display-name>Service name</display-name>
    <description>Service name for Logsearch Portal (label)</description>
    <value>Spark</value>
    <on-ambari-upgrade add="false"/>
  </property>
  <property>
    <name>component_mappings</name>
    <display-name>Component mapping</display-name>
    <description>Logsearch component logid mapping list (e.g.: COMPONENT1:logid1,logid2;COMPONENT2:logid3)</description>
    <value>SPARK_JOBHISTORYSERVER:spark_jobhistory_server;SPARK_THRIFTSERVER:spark_thriftserver;LIVY_SERVER:livy_server</value>
    <on-ambari-upgrade add="false"/>
  </property>
  <property>
    <name>content</name>
    <display-name>Logfeeder Config</display-name>
    <description>Metadata jinja template for Logfeeder which contains grok patterns for reading service specific logs.</description>
    <value>
{
   "input":[
      {
       "type":"spark_jobhistory_server",
       "rowtype":"service",
       "path":"{{default('/configurations/spark-env/spark_log_dir', '/var/log/spark')}}/spark-*-org.apache.spark.deploy.history.HistoryServer*.out"
     },
     {
       "type":"spark_thriftserver",
       "rowtype":"service",
       "path":"{{default('/configurations/spark-env/spark_log_dir', '/var/log/spark')}}/spark-*-org.apache.spark.sql.hive.thriftserver.HiveThriftServer2*.out"
     },
     {
       "type":"livy_server",
       "rowtype":"service",
       "path":"{{default('/configurations/livy-env/livy_log_dir', '/var/log/livy')}}/livy-livy-server.out"
     }
   ],
   "filter":[
      {
          "filter":"grok",
          "conditions":{
            "fields":{
              "type":[
                "spark_jobhistory_server",
                "spark_thriftserver",
                "livy_server"
              ]
             }
          },
          "log4j_format":"",
          "multiline_pattern":"^(%{SPARK_DATESTAMP:logtime}%{SPACE}%{LOGLEVEL:level})",
          "message_pattern":"(?m)^%{SPARK_DATESTAMP:logtime}%{SPACE}%{LOGLEVEL:level}%{SPACE}%{JAVAFILE:file}:%{SPACE}%{GREEDYDATA:log_message}",
          "post_map_values":{
            "logtime":{
              "map_date":{
                "target_date_pattern":"yy/MM/dd HH:mm:ss"
              }
             },
            "level":{
              "map_fieldvalue":{
                "pre_value":"WARNING",
                "post_value":"WARN"
              }
             }
           }
      }
   ]
}
    </value>
    <value-attributes>
      <type>content</type>
      <show-property-name>false</show-property-name>
    </value-attributes>
    <on-ambari-upgrade add="false"/>
  </property>
</configuration>
