<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
<configuration supports_adding_forbidden="true">
  <property>
    <name>spark_daemon_memory</name>
    <value>512</value>
    <description>Memory for Master, Worker and history server (default: 1G)</description>
    <value-attributes>
      <type>int</type>
      <unit>MB</unit>
    </value-attributes>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>spark_master_port</name>
    <value>6190</value>
    <description>Start the master on this port</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>spark_master_webui_port</name>
    <value>6180</value>
    <description>Port for the master web UI</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>spark_worker_cores</name>
    <value>4</value>
    <description>Total number of cores to allow Spark applications to use on the machine</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>spark_worker_memory</name>
    <value>2048</value>
    <description>Total amount of memory to allow Spark applications to use on the machine</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>spark_worker_webui_port</name>
    <value>6181</value>
    <description>Port for the worker web UI</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>content</name>
    <description>This is the jinja template for spark-env.sh file</description>
    <value>
      #!/usr/bin/env bash

      # This file is sourced when running various Spark programs.
      # Copy it as spark-env.sh and edit that to configure Spark for your site.

      # Generic options for the daemons used in the standalone deploy mode

      export SPARK_MASTER_HOST={{hostname}}
      export SPARK_MASTER_PORT={{spark_master_port}}
      export SPARK_MASTER_WEBUI_PORT={{spark_master_webui_port}}
      export SPARK_WORKER_CORES={{spark_worker_cores}}
      export SPARK_WORKER_MEMORY={{spark_worker_memory}}m
      export SPARK_WORKER_WEBUI_PORT={{spark_worker_webui_port}}
      export SPARK_WORKER_DIR={{ams_ad_log_dir}}

      export SPARK_MASTER_OPTS=$SPARK_MASTER_OPTS
      export SPARK_WORKER_OPTS=$SPARK_WORKER_OPTS

      export SPARK_MASTER_PORT={{spark_master_port}}
      # Alternate conf dir. (Default: ${SPARK_HOME}/conf)
      export SPARK_CONF_DIR={{ams_ad_conf_dir}}

      # Where log files are stored.(Default:${SPARK_HOME}/logs)
      export SPARK_LOG_DIR={{ams_ad_log_dir}}

      # Where the pid file is stored. (Default: /tmp)
      export SPARK_PID_DIR={{ams_ad_pid_dir}}

      #Memory for Master, Worker and history server (default: 1024MB)
      export SPARK_DAEMON_MEMORY={{spark_daemon_memory}}m

      # A string representing this instance of spark.(Default: $USER)
      SPARK_IDENT_STRING=$USER

      # The scheduling priority for daemons. (Default: 0)
      SPARK_NICENESS=0

      # Options read in YARN client mode
      #SPARK_EXECUTOR_INSTANCES="2" #Number of workers to start (Default: 2)
      #SPARK_EXECUTOR_CORES="1" #Number of cores for the workers (Default: 1).
      #SPARK_EXECUTOR_MEMORY="1G" #Memory per Worker (e.g. 1000M, 2G) (Default: 1G)
      #SPARK_DRIVER_MEMORY="512M" #Memory for Master (e.g. 1000M, 2G) (Default: 512 Mb)
      #SPARK_YARN_APP_NAME="spark" #The name of your application (Default: Spark)
      #SPARK_YARN_QUEUE="default" #The hadoop queue to use for allocation requests (Default: default)
      #SPARK_YARN_DIST_FILES="" #Comma separated list of files to be distributed with the job.
      #SPARK_YARN_DIST_ARCHIVES="" #Comma separated list of archives to be distributed with the job.

      #export HADOOP_HOME=${HADOOP_HOME:-{{hadoop_home}}}
      #export HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-{{hadoop_conf_dir}}}

      # The java implementation to use.
      export JAVA_HOME={{java_home}}

      #HDP Version
      export HDP_VERSION=3.0.0

    </value>
    <value-attributes>
      <type>content</type>
    </value-attributes>
    <on-ambari-upgrade add="false"/>
  </property>
</configuration>
