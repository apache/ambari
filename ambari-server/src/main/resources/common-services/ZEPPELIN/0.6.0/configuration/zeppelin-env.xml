<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->
<configuration>
  <property>
    <name>zeppelin_pid_dir</name>
    <value>/var/run/zeppelin</value>
    <description>Dir containing process ID file</description>
    <value-attributes>
      <type>directory</type>
      <overridable>false</overridable>
      <editable-only-at-install>true</editable-only-at-install>
    </value-attributes>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>zeppelin_user</name>
    <display-name>Zeppelin User</display-name>
    <value>zeppelin</value>
    <property-type>USER</property-type>
    <description>User zeppelin daemon runs as</description>
    <value-attributes>
      <type>user</type>
      <overridable>false</overridable>
      <user-groups>
        <property>
          <type>zeppelin-env</type>
          <name>zeppelin_group</name>
        </property>
        <property>
          <type>cluster-env</type>
          <name>user_group</name>
        </property>
      </user-groups>
    </value-attributes>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>zeppelin_group</name>
    <display-name>Zeppelin Group</display-name>
    <value>zeppelin</value>
    <property-type>GROUP</property-type>
    <description>zeppelin group</description>
    <value-attributes>
      <type>user</type>
      <overridable>false</overridable>
    </value-attributes>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>zeppelin_log_dir</name>
    <value>/var/log/zeppelin</value>
    <description>Zeppelin Log dir</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>zeppelin_env_content</name>
    <description>This is the jinja template for zeppelin-env.sh file</description>
    <value>
# export JAVA_HOME=
export JAVA_HOME={{java64_home}}
# export MASTER=                              # Spark master url. eg. spark://master_addr:7077. Leave empty if you want to use local mode.
export MASTER=yarn-client
export SPARK_YARN_JAR={{spark_jar}}
# export ZEPPELIN_JAVA_OPTS                   # Additional jvm options. for example, export ZEPPELIN_JAVA_OPTS="-Dspark.executor.memory=8g -Dspark.cores.max=16"
# export ZEPPELIN_MEM                         # Zeppelin jvm mem options Default -Xms1024m -Xmx1024m -XX:MaxPermSize=512m
# export ZEPPELIN_INTP_MEM                    # zeppelin interpreter process jvm mem options. Default -Xms1024m -Xmx1024m -XX:MaxPermSize=512m
# export ZEPPELIN_INTP_JAVA_OPTS              # zeppelin interpreter process jvm options.
# export ZEPPELIN_SSL_PORT                    # ssl port (used when ssl environment variable is set to true)

# export ZEPPELIN_LOG_DIR                     # Where log files are stored.  PWD by default.
export ZEPPELIN_LOG_DIR={{zeppelin_log_dir}}
# export ZEPPELIN_PID_DIR                     # The pid files are stored. ${ZEPPELIN_HOME}/run by default.
export ZEPPELIN_PID_DIR={{zeppelin_pid_dir}}
# export ZEPPELIN_WAR_TEMPDIR                 # The location of jetty temporary directory.
# export ZEPPELIN_NOTEBOOK_DIR                # Where notebook saved
# export ZEPPELIN_NOTEBOOK_HOMESCREEN         # Id of notebook to be displayed in homescreen. ex) 2A94M5J1Z
# export ZEPPELIN_NOTEBOOK_HOMESCREEN_HIDE    # hide homescreen notebook from list when this value set to "true". default "false"
# export ZEPPELIN_NOTEBOOK_S3_BUCKET          # Bucket where notebook saved
# export ZEPPELIN_NOTEBOOK_S3_ENDPOINT        # Endpoint of the bucket
# export ZEPPELIN_NOTEBOOK_S3_USER            # User in bucket where notebook saved. For example bucket/user/notebook/2A94M5J1Z/note.json
# export ZEPPELIN_IDENT_STRING                # A string representing this instance of zeppelin. $USER by default.
# export ZEPPELIN_NICENESS                    # The scheduling priority for daemons. Defaults to 0.
# export ZEPPELIN_INTERPRETER_LOCALREPO       # Local repository for interpreter's additional dependency loading
# export ZEPPELIN_NOTEBOOK_STORAGE            # Refers to pluggable notebook storage class, can have two classes simultaneously with a sync between them (e.g. local and remote).
# export ZEPPELIN_NOTEBOOK_ONE_WAY_SYNC       # If there are multiple notebook storages, should we treat the first one as the only source of truth?
# export ZEPPELIN_NOTEBOOK_PUBLIC             # Make notebook public by default when created, private otherwise
export ZEPPELIN_INTP_CLASSPATH_OVERRIDES="{{external_dependency_conf}}"
#### Spark interpreter configuration ####

## Kerberos ticket refresh setting
##
export KINIT_FAIL_THRESHOLD=5
export KERBEROS_REFRESH_INTERVAL=1d

## Use provided spark installation ##
## defining SPARK_HOME makes Zeppelin run spark interpreter process using spark-submit
##
# export SPARK_HOME                           # (required) When it is defined, load it instead of Zeppelin embedded Spark libraries
# export SPARK_HOME={{spark_home}}
# export SPARK_SUBMIT_OPTIONS                 # (optional) extra options to pass to spark submit. eg) "--driver-memory 512M --executor-memory 1G".
# export SPARK_APP_NAME                       # (optional) The name of spark application.

## Use embedded spark binaries ##
## without SPARK_HOME defined, Zeppelin still able to run spark interpreter process using embedded spark binaries.
## however, it is not encouraged when you can define SPARK_HOME
##
# Options read in YARN client mode
# export HADOOP_CONF_DIR                      # yarn-site.xml is located in configuration directory in HADOOP_CONF_DIR.
export HADOOP_CONF_DIR=/etc/hadoop/conf
# Pyspark (supported with Spark 1.2.1 and above)
# To configure pyspark, you need to set spark distribution's path to 'spark.home' property in Interpreter setting screen in Zeppelin GUI
# export PYSPARK_PYTHON                       # path to the python command. must be the same path on the driver(Zeppelin) and all workers.
# export PYTHONPATH

## Spark interpreter options ##
##
# export ZEPPELIN_SPARK_USEHIVECONTEXT        # Use HiveContext instead of SQLContext if set true. true by default.
# export ZEPPELIN_SPARK_CONCURRENTSQL         # Execute multiple SQL concurrently if set true. false by default.
# export ZEPPELIN_SPARK_IMPORTIMPLICIT        # Import implicits, UDF collection, and sql if set true. true by default.
# export ZEPPELIN_SPARK_MAXRESULT             # Max number of Spark SQL result to display. 1000 by default.
# export ZEPPELIN_WEBSOCKET_MAX_TEXT_MESSAGE_SIZE       # Size in characters of the maximum text message to be received by websocket. Defaults to 1024000


#### HBase interpreter configuration ####

## To connect to HBase running on a cluster, either HBASE_HOME or HBASE_CONF_DIR must be set

# export HBASE_HOME=                          # (require) Under which HBase scripts and configuration should be
# export HBASE_CONF_DIR=                      # (optional) Alternatively, configuration directory can be set to point to the directory that has hbase-site.xml

# export ZEPPELIN_IMPERSONATE_CMD             # Optional, when user want to run interpreter as end web user. eg) 'sudo -H -u ${ZEPPELIN_IMPERSONATE_USER} bash -c '

    </value>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>zeppelin.executor.mem</name>
    <value>512m</value>
    <description>Executor memory to use (e.g. 512m or 1g)</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>zeppelin.executor.instances</name>
    <value>2</value>
    <description>Number of executor instances to use (e.g. 2)</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>zeppelin.spark.jar.dir</name>
    <value>/apps/zeppelin</value>
    <description>Shared location where zeppelin spark jar will be copied to. Should be accesible
      by all cluster nodes
    </description>
    <on-ambari-upgrade add="true"/>
  </property>

  <property>
    <name>zeppelin.server.kerberos.principal</name>
    <value/>
    <value-attributes>
      <empty-value-valid>true</empty-value-valid>
    </value-attributes>
    <description>
      Kerberos principal name for the Zeppelin.
    </description>
    <property-type>KERBEROS_PRINCIPAL</property-type>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>zeppelin.server.kerberos.keytab</name>
    <value/>
    <value-attributes>
      <empty-value-valid>true</empty-value-valid>
    </value-attributes>
    <description>
      Location of the kerberos keytab file for the Zeppelin.
    </description>
    <on-ambari-upgrade add="true"/>
  </property>
</configuration>
