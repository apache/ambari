<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->
<view>
    <name>FILES</name>
    <label>Files</label>
    <version>1.0.0</version>
    <build>${env.BUILD_NUMBER}</build>

    <min-ambari-version>2.0.*</min-ambari-version>

    <validator-class>org.apache.ambari.view.filebrowser.PropertyValidator</validator-class>

    <parameter>
        <name>webhdfs.url</name>
        <description>Enter the WebHDFS FileSystem URI. Typically this is the dfs.namenode.http-address
            property in the hdfs-site.xml configuration. URL must be accessible from Ambari Server.</description>
        <label>WebHDFS FileSystem URI</label>
        <required>true</required>
        <cluster-config>core-site/fs.defaultFS</cluster-config>
    </parameter>
    <parameter>
        <name>webhdfs.nameservices</name>
        <description>Comma-separated list of nameservices. Value of hdfs-site/dfs.nameservices property</description>
        <label>Logical name of the NameNode cluster</label>
        <required>false</required>
        <cluster-config>hdfs-site/dfs.nameservices</cluster-config>
    </parameter>
    <parameter>
        <name>webhdfs.ha.namenodes.list</name>
        <description>Comma-separated list of namenodes for a given nameservice.
            Value of hdfs-site/dfs.ha.namenodes.[nameservice] property</description>
        <label>List of NameNodes</label>
        <required>false</required>
        <cluster-config>fake</cluster-config>
    </parameter>
    <parameter>
        <name>webhdfs.ha.namenode.rpc-address.list</name>
        <description>Comma separated RPC address for name nodes.</description>
        <label>Comma separated NameNode RPC Addresses</label>
        <required>false</required>
        <cluster-config>fake</cluster-config>
    </parameter>
    <parameter>
        <name>webhdfs.ha.namenode.http-address.list</name>
        <description>Comma separated WebHDFS address for name nodes.</description>
        <label>Comma separated NameNode HTTP (WebHDFS) Addresses</label>
        <required>false</required>
        <cluster-config>fake</cluster-config>
    </parameter>
    <parameter>
        <name>webhdfs.ha.namenode.https-address.list</name>
        <description>Comma separated WebHDFS Https addresses for name nodes.</description>
        <label>Comma separated NameNode HTTPS (WebHDFS) Addresses</label>
        <required>false</required>
        <cluster-config>fake</cluster-config>
    </parameter>
    <parameter>
        <name>webhdfs.client.failover.proxy.provider</name>
        <description>The Java class that HDFS clients use to contact the Active NameNode
            Value of hdfs-site/dfs.client.failover.proxy.provider.[nameservice] property</description>
        <label>Failover Proxy Provider</label>
        <required>false</required>
        <cluster-config>fake</cluster-config>
    </parameter>
    <parameter>
        <name>hdfs.umask-mode</name>
        <description>The umask used when creating files and directories. Defaults to 022</description>
        <label>Umask</label>
        <default-value>022</default-value>
        <required>false</required>
        <cluster-config>hdfs-site/fs.permissions.umask-mode</cluster-config>
    </parameter>
    <parameter>
        <name>hdfs.auth_to_local</name>
        <description>Auth to Local Configuration</description>
        <label>Auth To Local</label>
        <required>false</required>
        <cluster-config>core-site/hadoop.security.auth_to_local</cluster-config>
    </parameter>

    <parameter>
        <name>webhdfs.username</name>
        <description>doAs for proxy user for HDFS. By default, uses the currently logged-in Ambari user.</description>
        <label>WebHDFS Username</label>
        <default-value>${username}</default-value>
        <required>false</required>
    </parameter>
    <parameter>
        <name>webhdfs.auth</name>
        <description>Semicolon-separated authentication configs.</description>
        <placeholder>auth=SIMPLE</placeholder>
        <label>WebHDFS Authorization</label>
        <required>false</required>
    </parameter>
    <parameter>
        <name>tmp.dir</name>
        <description>HDFS directory path to store temporary files required for the view operations.</description>
        <label>Temporary HDFS Directory</label>
        <placeholder>/user/${username}/files-view/tmp</placeholder>
        <default-value>/user/${username}/files-view/tmp</default-value>
        <required>true</required>
    </parameter>
    <parameter>
        <name>view.conf.keyvalues</name>
        <description>The key values that will be copied to hdfs connection configuration verbatim. Format : key1=value1;
          key2=value2</description>
        <label>View Configs</label>
        <required>false</required>
    </parameter>

    <resource>
        <name>files</name>
        <service-class>org.apache.ambari.view.filebrowser.FileBrowserService</service-class>
    </resource>

    <auto-instance>
        <name>AUTO_FILES_INSTANCE</name>
        <label>Files View</label>
        <description>This view instance is auto created when the HDFS service is added to a cluster.</description>
        <stack-id>HDP-*</stack-id>
        <services>
          <service>HDFS</service>
        </services>
        <roles>
            <role>CLUSTER.ADMINISTRATOR</role>
            <role>CLUSTER.OPERATOR</role>
            <role>SERVICE.ADMINISTRATOR</role>
            <role>SERVICE.OPERATOR</role>
            <role>CLUSTER.USER</role>
        </roles>
    </auto-instance>
</view>
