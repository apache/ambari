<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->
<view>
    <name>HIVE</name>
    <label>Hive</label>
    <version>1.0.0</version>
    <build>${env.BUILD_NUMBER}</build>

    <min-ambari-version>2.0.*</min-ambari-version>

    <validator-class>org.apache.ambari.view.hive.PropertyValidator</validator-class>
    <view-class>org.apache.ambari.view.hive.HiveViewImpl</view-class>

    <!-- Hive Configs -->
    <parameter>
      <name>hive.host</name>
      <description>Enter the HiveServer2 host. Host must be accessible from Ambari Server.</description>
      <label>HiveServer2 Host</label>
      <placeholder>127.0.0.1</placeholder>
      <cluster-config>fake</cluster-config>
      <required>true</required>
    </parameter>

    <parameter>
      <name>hive.port</name>
      <description>HiveServer2 Thrift port (example: 10000).</description>
      <label>HiveServer2 Thrift port</label>
      <placeholder>10000</placeholder>
      <default-value>10000</default-value>
      <cluster-config>hive-site/hive.server2.thrift.port</cluster-config>
      <required>true</required>
    </parameter>

    <parameter>
        <name>hive.http.port</name>
        <description>HiveServer2 Http port (example: 10001).</description>
        <label>HiveServer2 Http port</label>
        <placeholder>10001</placeholder>
        <default-value>10001</default-value>
        <cluster-config>hive-site/hive.server2.thrift.http.port</cluster-config>
        <required>true</required>
    </parameter>

    <parameter>
        <name>hive.http.path</name>
        <description>HiveServer2 Http path (example: cliservice).</description>
        <label>HiveServer2 Http path</label>
        <placeholder>cliservice</placeholder>
        <default-value>cliservice</default-value>
        <cluster-config>hive-site/hive.server2.thrift.http.path</cluster-config>
        <required>true</required>
    </parameter>

    <parameter>
        <name>hive.transport.mode</name>
        <description>HiveServer2 Transport Mode (example: http/binary).</description>
        <label>HiveServer2 Transport Mode</label>
        <placeholder>binary</placeholder>
        <default-value>binary</default-value>
        <cluster-config>hive-site/hive.server2.transport.mode</cluster-config>
        <required>true</required>
    </parameter>

    <parameter>
      <name>hive.auth</name>
      <description>Semicolon-separated authentication configs.</description>
      <label>Hive Authentication</label>
      <placeholder>auth=NONE</placeholder>
      <default-value>auth=NONE</default-value>
      <required>false</required>
    </parameter>

    <parameter>
        <name>hive.metastore.warehouse.dir</name>
        <description>Hive Metastore directory (example: /apps/hive/warehouse)</description>
        <label>Hive Metastore directory</label>
        <placeholder>/apps/hive/warehouse</placeholder>
        <default-value>/apps/hive/warehouse</default-value>
        <cluster-config>hive-site/hive.metastore.warehouse.dir</cluster-config>
        <required>false</required>
    </parameter>

    <!-- HDFS Configs -->
    <parameter>
        <name>webhdfs.url</name>
        <description>Enter the WebHDFS FileSystem URI. Typically this is the dfs.namenode.http-address
            property in the hdfs-site.xml configuration. URL must be accessible from Ambari Server.</description>
        <label>WebHDFS FileSystem URI</label>
        <placeholder>webhdfs://namenode:50070</placeholder>
        <required>true</required>
        <cluster-config>core-site/fs.defaultFS</cluster-config>
    </parameter>
    <parameter>
        <name>webhdfs.nameservices</name>
        <description>Comma-separated list of nameservices. Value of hdfs-site/dfs.nameservices property</description>
        <label>Logical name of the NameNode cluster</label>
        <required>false</required>
        <cluster-config>hdfs-site/dfs.nameservices</cluster-config>
    </parameter>
    <parameter>
        <name>webhdfs.ha.namenodes.list</name>
        <description>Comma-separated list of namenodes for a given nameservice.
          Value of hdfs-site/dfs.ha.namenodes.[nameservice] property</description>
        <label>List of NameNodes</label>
        <required>false</required>
        <cluster-config>fake</cluster-config>
    </parameter>
    <parameter>
        <name>webhdfs.ha.namenode.rpc-address.nn1</name>
        <description>RPC address for first name node.
          Value of hdfs-site/dfs.namenode.rpc-address.[nameservice].[namenode1] property</description>
        <label>First NameNode RPC Address</label>
        <required>false</required>
        <cluster-config>fake</cluster-config>
    </parameter>
    <parameter>
        <name>webhdfs.ha.namenode.rpc-address.nn2</name>
        <description>RPC address for second name node.
          Value of hdfs-site/dfs.namenode.rpc-address.[nameservice].[namenode2] property</description>
        <label>Second NameNode RPC Address</label>
        <required>false</required>
        <cluster-config>fake</cluster-config>
    </parameter>
    <parameter>
        <name>webhdfs.ha.namenode.http-address.nn1</name>
        <description>WebHDFS address for first name node.
          Value of hdfs-site/dfs.namenode.http-address.[nameservice].[namenode1] property</description>
        <label>First NameNode HTTP (WebHDFS) Address</label>
        <required>false</required>
        <cluster-config>fake</cluster-config>
    </parameter>
    <parameter>
        <name>webhdfs.ha.namenode.http-address.nn2</name>
        <description>WebHDFS address for second name node.
          Value of hdfs-site/dfs.namenode.http-address.[nameservice].[namenode2] property</description>
        <label>Second NameNode HTTP (WebHDFS) Address</label>
        <required>false</required>
        <cluster-config>fake</cluster-config>
    </parameter>
    <parameter>
        <name>webhdfs.client.failover.proxy.provider</name>
        <description>The Java class that HDFS clients use to contact the Active NameNode
          Value of hdfs-site/dfs.client.failover.proxy.provider.[nameservice] property</description>
        <label>Failover Proxy Provider</label>
        <required>false</required>
        <cluster-config>fake</cluster-config>
    </parameter>

    <parameter>
        <name>webhdfs.username</name>
        <description>doAs for proxy user for HDFS. By default, uses the currently logged-in Ambari user.</description>
        <label>WebHDFS Username</label>
        <default-value>${username}</default-value>
        <required>false</required>
    </parameter>

    <parameter>
        <name>webhdfs.auth</name>
        <description>Semicolon-separated authentication configs.</description>
        <label>WebHDFS Authentication</label>
        <placeholder>auth=SIMPLE</placeholder>
        <required>false</required>
    </parameter>

    <parameter>
        <name>hdfs.umask-mode</name>
        <description>The umask used when creating files and directories. Defaults to 022</description>
        <label>Umask</label>
        <default-value>022</default-value>
        <required>false</required>
        <cluster-config>hdfs-site/fs.permissions.umask-mode</cluster-config>
    </parameter>

    <parameter>
        <name>hdfs.auth_to_local</name>
        <description>Auth to Local Configuration</description>
        <label>Auth To Local</label>
        <required>false</required>
        <cluster-config>core-site/hadoop.security.auth_to_local</cluster-config>
    </parameter>

    <!-- General Configs -->

    <parameter>
        <name>views.tez.instance</name>
        <description>Instance name of Tez view.</description>
        <label>Instance name of Tez view</label>
        <required>false</required>
    </parameter>

    <parameter>
        <name>scripts.dir</name>
        <description>HDFS directory path to store Hive scripts.</description>
        <label>Scripts HDFS Directory</label>
        <placeholder>/user/${username}/hive/scripts</placeholder>
        <default-value>/user/${username}/hive/scripts</default-value>
        <required>true</required>
    </parameter>

    <parameter>
        <name>jobs.dir</name>
        <description>HDFS directory path to store Hive job status.</description>
        <label>Jobs HDFS Directory</label>
        <placeholder>/user/${username}/hive/jobs</placeholder>
        <default-value>/user/${username}/hive/jobs</default-value>
        <required>true</required>
    </parameter>

    <parameter>
        <name>scripts.settings.defaults-file</name>
        <description>File path for saving default settings for query</description>
        <label>Default script settings file</label>
        <default-value>/user/${username}/.${instanceName}.defaultSettings</default-value>
        <required>true</required>
    </parameter>

    <parameter>
        <name>yarn.ats.url</name>
        <description>The URL to the YARN Application Timeline Server, used to provide Jobs information, typically, this is the yarn.timeline-service.webapp.address property in the yarn-site.xml configuration.</description>
        <label>YARN Application Timeline Server URL</label>
        <placeholder>http://yarn.ats.address:8188</placeholder>
        <cluster-config>yarn-site/yarn.timeline-service.webapp.address</cluster-config>
        <required>true</required>
    </parameter>

    <parameter>
        <name>yarn.resourcemanager.url</name>
        <description>The URL to the YARN ResourceManager, used to provide YARN Application data. If YARN ResourceManager HA is enabled, provide a comma separated list of URLs for all the Resource Managers.</description>
        <label>YARN ResourceManager URL</label>
        <placeholder>http://yarn.resourcemanager.address:8088</placeholder>
        <cluster-config>yarn-site/yarn.resourcemanager.webapp.address</cluster-config>
        <required>true</required>
    </parameter>

    <resource>
        <name>savedQuery</name>
        <plural-name>savedQueries</plural-name>
        <id-property>id</id-property>
        <resource-class>org.apache.ambari.view.hive.resources.savedQueries.SavedQuery</resource-class>
        <provider-class>org.apache.ambari.view.hive.resources.savedQueries.SavedQueryResourceProvider</provider-class>
        <service-class>org.apache.ambari.view.hive.resources.savedQueries.SavedQueryService</service-class>
    </resource>

    <resource>
        <name>fileResource</name>
        <plural-name>fileResources</plural-name>
        <id-property>id</id-property>
        <resource-class>org.apache.ambari.view.hive.resources.resources.FileResourceItem</resource-class>
        <provider-class>org.apache.ambari.view.hive.resources.resources.FileResourceResourceProvider</provider-class>
        <service-class>org.apache.ambari.view.hive.resources.resources.FileResourceService</service-class>
    </resource>

    <resource>
        <name>udf</name>
        <plural-name>udfs</plural-name>
        <id-property>id</id-property>
        <resource-class>org.apache.ambari.view.hive.resources.udfs.UDF</resource-class>
        <provider-class>org.apache.ambari.view.hive.resources.udfs.UDFResourceProvider</provider-class>
        <service-class>org.apache.ambari.view.hive.resources.udfs.UDFService</service-class>
    </resource>

    <resource>
        <name>job</name>
        <plural-name>jobs</plural-name>
        <id-property>id</id-property>
        <resource-class>org.apache.ambari.view.hive.resources.jobs.viewJobs.JobImpl</resource-class>
        <provider-class>org.apache.ambari.view.hive.resources.jobs.JobResourceProvider</provider-class>
        <service-class>org.apache.ambari.view.hive.resources.jobs.JobService</service-class>
    </resource>

    <resource>
        <name>upload</name>
        <plural-name>uploads</plural-name>
        <service-class>org.apache.ambari.view.hive.resources.uploads.UploadService</service-class>
    </resource>

    <resource>
        <name>file</name>
        <service-class>org.apache.ambari.view.hive.resources.files.FileService</service-class>
    </resource>

    <resource>
        <name>ddl</name>
        <service-class>org.apache.ambari.view.hive.resources.browser.HiveBrowserService</service-class>
    </resource>

    <resource>
        <name>hive</name>
        <service-class>org.apache.ambari.view.hive.HelpService</service-class>
    </resource>

    <persistence>
        <entity>
            <class>org.apache.ambari.view.hive.resources.jobs.viewJobs.JobImpl</class>
            <id-property>id</id-property>
        </entity>
        <entity>
            <class>org.apache.ambari.view.hive.resources.jobs.StoredOperationHandle</class>
            <id-property>id</id-property>
        </entity>
        <entity>
            <class>org.apache.ambari.view.hive.resources.savedQueries.SavedQuery</class>
            <id-property>id</id-property>
        </entity>
        <entity>
            <class>org.apache.ambari.view.hive.resources.udfs.UDF</class>
            <id-property>id</id-property>
        </entity>
        <entity>
            <class>org.apache.ambari.view.hive.resources.resources.FileResourceItem</class>
            <id-property>id</id-property>
        </entity>
        <entity>
            <class>org.apache.ambari.view.hive.TestBean</class>
            <id-property>id</id-property>
        </entity>
    </persistence>

    <auto-instance>
        <name>AUTO_HIVE_INSTANCE</name>
        <label>Hive View</label>
        <description>This view instance is auto created when the Hive service is added to a cluster.</description>
        <stack-id>HDP-2.*</stack-id>
        <services>
            <service>HIVE</service>
        </services>
    </auto-instance>
</view>
