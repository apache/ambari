~~ Licensed to the Apache Software Foundation (ASF) under one or more
~~ contributor license agreements.  See the NOTICE file distributed with
~~ this work for additional information regarding copyright ownership.
~~ The ASF licenses this file to You under the Apache License, Version 2.0
~~ (the "License"); you may not use this file except in compliance with
~~ the License.  You may obtain a copy of the License at
~~
~~     http://www.apache.org/licenses/LICENSE-2.0
~~
~~ Unless required by applicable law or agreed to in writing, software
~~ distributed under the License is distributed on an "AS IS" BASIS,
~~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
~~ See the License for the specific language governing permissions and
~~ limitations under the License.
~~
Ambari Example Scenarios

  These are examples scenarios of typical usage cases.

* Installing Ambari

  On controller:

-------
$ rpm -i ambari-0.1.0-1.rpm
$ ambari configure -agent-password my.pw
$ ambari add-user -user sue -kerberos
$ ambari controller
-------

  On slaves using pdsh:

-------
$ rpm -i ambari-0.1.0-1.rpm
$ ambari configure -controller controller.my.domain.com -agent-password my.pw
$ ambari agent
-------

* Creating a cluster using CLI

  Create file cluster1.json with the specific configuration
  alterations for cluster1.

-------
{"@parentName":"hadoop-security",
 "configuration": {
   "category": [
     {"@name": "ambari",
      "property": [
        {"@name": "data.dirs", "@value": "/data/*"},
        {"@name": "keytab.dir", "@value": " /etc/security/keytab"},
        {"@name": "user.realm", "@value": "MY.DOMAIN.COM"}]},
     {"@name": "hadoop-env",
      "property": [
        {"@name": "HADOOP_CLIENT_OPTS",
         "@value": "-Xmx256m ${HADOOP_CLIENT_OPTS}"}]}]},
 "components": [
   {"@name":"hdfs",
    "configuration": {
      "category": [
        {"@name": "hadoop-env",
         property: [
           {"@name": "HADOOP_NAMENODE_OPTS",
            "@value": "-Xmx512m -Dsecurity.audit.logger=INFO,DRFAS
                       -Dhdfs.audit.logger=INFO,DRFAAUDIT"}]}]}}]}
-------

  Run the commands using the CLI and Kerberos authentication. The first command 
  creates the stack and the second creates a cluster based on that stack using 
  the machines host00-99.

-------
$ ambari stack create -name cluster1 -file cluster1.json
$ ambari cluster create -name cluster1 -stack cluster1 -nodes host00-99 \
    -goalstate active -role namenode=host00 -role jobtracker=host01 \
    -role client=host98-99 -wait
-------

* Upgrading a cluster using CLI

  Create file cluster1-update.json that updates the version of the Hadoop 
  component to a new version.

-------
{"components":
  {"@name":"hadoop", "@version":"0.20.205.1"}
}
-------

  Run the command to update the stack and cluster to the new version and wait
  for the command to complete.

-------
$ ambari stack update -name cluster1 -file cluster1-update.json
$ ambari cluster update -name cluster1 -stack cluster1 -wait
-------

* Creating a cluster using REST

-------
$ curl --negotiate -X PUT -T cluster1.json -H 'ContentType: application/json' \
     http://ambari.my.domain.com:4080/rest/stack/cluster1
$ curl --negotiate -X PUT -T - -H 'ContentType: application/json' \
     http://ambari.my.domain.com:4080/rest/cluster/cluster1 << EOF
{"@stackName": "cluster1",
 "@goalState": "active",
 "@nodes": "host00-99"
 "roleToNodes": [{"@role": "namenode", "@nodes": "host00"},
                 {"@role": "jobtracker", "@nodes": "host01"},
                 {"@role": "client", "@nodes": "host98,host99"}]
}
EOF
-------

* Upgrade a cluster using REST

-------
$ curl --negotiate -X PUT -T - -H 'ContentType: application/json' \
     http://ambari.my.domain.com:4080/rest/stack/cluster1 << EOF
{"components": {"@name":"hadoop", "@version":"0.20.205.1"}}
EOF
$ curl --negotiate -X PUT -T - -H 'ContentType: application/json' \
     http://ambari.my.domain.com:4080/rest/cluster/cluster1 << EOF
{"@stackName": "cluster1"}
EOF
-------
